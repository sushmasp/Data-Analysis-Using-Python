{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question-1:\n",
    "\n",
    "Analysis-2:\n",
    "\n",
    "Let's take the crtical words as 'bankrupt','fraud','deal','agreement'\n",
    "To fetch the count of these crtitcal words in the sent emails of all persons by each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sent mails from all persons:  57653\n"
     ]
    }
   ],
   "source": [
    "#To fetch all the sent files of each person\n",
    "import os\n",
    "from glob import glob\n",
    "import glob\n",
    "\n",
    "cwd_path = os.getcwd() \n",
    "root_dir_path=os.path.abspath(os.path.join(cwd_path, os.pardir)) \n",
    "root=root_dir_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "pattern = \"*\"\n",
    "\n",
    "all_sent_mails=[]\n",
    "\n",
    "sent_start_dir1=root+'/data/enron/maildir/'\n",
    "\n",
    "import os\n",
    "test_directory = sent_start_dir1\n",
    "\n",
    "for child in os.listdir(test_directory):\n",
    "    test_path = os.path.join(test_directory, child)\n",
    "    if os.path.isdir(test_path):\n",
    "        #print(test_path) \n",
    "        #t=test_path.find('/',0)# All persons folders\n",
    "        #print(t)\n",
    "        #if test_path in path:\n",
    "        if test_path+'/sent':\n",
    "            new_path=test_path+'/sent'\n",
    "            mails=glob.glob(new_path+'/*')\n",
    "            all_sent_mails+=mails\n",
    "            \n",
    "print('Total number of sent mails from all persons: ',len(all_sent_mails))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# To check for critical words in each mail;\n",
    "#if present add it a dictionary corresponding to the year in which the mail had been sent\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "from email.parser import Parser\n",
    "import email\n",
    "\n",
    "year_section_dictionary={} #To store year-person-mailcount\n",
    "\n",
    "for filename in all_sent_mails:\n",
    "\n",
    "    with open(filename,'r',encoding='utf-8',errors='ignore') as file:\n",
    "        email = Parser().parsestr(file.read())\n",
    "        year=str(email['Date'][11:15]) # Year in which email was sent\n",
    "        if year==' 200': year=year+'0'\n",
    "        wnl = nltk.WordNetLemmatizer()\n",
    "        sent_words=[]\n",
    "        content = email.get_payload()\n",
    "        end = content.find('From',0)\n",
    "        final_content=content[0:end]\n",
    "        tokens=nltk.word_tokenize(final_content)\n",
    "        for word in tokens:\n",
    "            word=word.lower() #Converting all words to lower case \n",
    "            table = str.maketrans(\"\", \"\", string.punctuation) #To remove punctuations\n",
    "            word = word.translate(table)\n",
    "            if word: #To remove blank strings which are formed if there is a punctuation as a word\n",
    "                            #(because of space spereation in a line)\n",
    "                if not word.isdigit(): # To remove numbers\n",
    "                    lemmatized_word=wnl.lemmatize(word) #Lemmatizing the words\n",
    "                    \n",
    "                    #If word is one of these common words do not add to list\n",
    "                    if not lemmatized_word in ['of','the','a','an','for','thanks','may','let','email','sr','do','thru','new','know','regard','more','ect','mr','time','cc','me','he','i','my','can','any','could','to','on','would','u','wa','and','your','yours','with','that','this','ha','http','no','at','from','all','not','in','you','is','s','will','be','it','we','have','are','or','our','am','pm','if','by','please']: #To ignore common words\n",
    "                        sent_words.append(lemmatized_word)\n",
    "\n",
    "        critical_words_list_in_file=[]\n",
    "        for word in sent_words:\n",
    "            #If the word is one of the 4 critical words, add to the list \n",
    "            if word in ['bankrupt','fraud','deal','agreement']: #These  4 are the critical words considered for analysis\n",
    "                critical_words_list_in_file.append(word)\n",
    "                #print(len(critical_words_list_in_file))\n",
    "        \n",
    "                        \n",
    "        #Creating a dictionary of year-critical_word-count\n",
    "        \n",
    "        if year in year_section_dictionary: #If year is present in dictionary\n",
    "            length=len(year_section_dictionary[year]) #Fetch the length of the list\n",
    "            if length==0: #If list is empty append a dictionary\n",
    "                 year_section_dictionary[year].append({word:0})\n",
    "            else: #If list is not empty\n",
    "                for i in range(length):\n",
    "                    for word in critical_words_list_in_file:\n",
    "                    \n",
    "                        if word in year_section_dictionary[year][i]: #Check for a section name in all entries of the list\n",
    "                            year_section_dictionary[year][i][word]+=1 #If present, increment the number\n",
    "                        \n",
    "        else: #If year is not present in dictionary\n",
    "            year_section_dictionary[year]=[]\n",
    "            year_section_dictionary[year].append({'bankrupt':0})\n",
    "            year_section_dictionary[year].append({'fraud':0})\n",
    "            year_section_dictionary[year].append({'deal':0})\n",
    "            year_section_dictionary[year].append({'agreement':0})\n",
    "            length=len(year_section_dictionary[year]) \n",
    "            for i in range(length):\n",
    "                for word in critical_words_list_in_file:\n",
    "                    if word in year_section_dictionary[year][i]: #Check for a section name \n",
    "                        year_section_dictionary[year][i][word]+=1\n",
    "    \n",
    "                \n",
    "print('Total number of years in the dictionary: ',len(year_section_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Data is written to file.\n"
     ]
    }
   ],
   "source": [
    "#Writing the output of the analysis i.e. Yearwise count of critical word to excel\n",
    "\n",
    "import xlsxwriter\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd() #To access the path of current working directory\n",
    "path=cwd+'/ana_2'\n",
    "\n",
    "# Create an excel workbook if not present and add a worksheet.\n",
    "if not os.path.exists(path+'/'+'Analysis_2_Critcal_Words_Yearwise.xlsx'):\n",
    "    workbook = xlsxwriter.Workbook(path+'/'+'Analysis_2_Critcal_Words_Yearwise.xlsx')\n",
    "\n",
    "    #Adding worksheet to the workbook\n",
    "    worksheet = workbook.add_worksheet('Critcal_Words_Yearwise_Data')\n",
    "\n",
    "    #Adding headers(title) to the columns\n",
    "    worksheet.write(0, 0, 'Year')\n",
    "    worksheet.write(0, 1, 'Critical Word')\n",
    "    worksheet.write(0, 2, 'Total Number of Words')\n",
    "\n",
    "    # Setting rows and columns indexes\n",
    "    row = 1\n",
    "    col = 0\n",
    "\n",
    "    dict_length=len(year_section_dictionary)\n",
    "\n",
    "    for key in year_section_dictionary.keys():\n",
    "        worksheet.write(row, col, key)#Year\n",
    "    \n",
    "        section_length=len(year_section_dictionary[key])\n",
    "        for i in range(section_length):\n",
    "            for sec_key,value in year_section_dictionary[key][i].items():\n",
    "                worksheet.write(row, col+1, sec_key) #Critical word\n",
    "                worksheet.write(row, col+2, value) #Count of critical word\n",
    "            row+=1\n",
    "    workbook.close()\n",
    "    print('Output Data is written to file.')\n",
    "    \n",
    "else:\n",
    "    print('The file already exists.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
